"""AI vÃ  Code Analysis Commands
Gá»™p cÃ¡c lá»‡nh AI tá»« bot vá»›i prefix "?" vÃ o bot chÃ­nh vá»›i prefix ";"
TÃ­ch há»£p Gemini AI vÃ  Grok AI Ä‘á»ƒ phÃ¢n tÃ­ch code vÃ  tráº£ lá»i cÃ¢u há»i
"""
import discord
from discord.ext import commands
import asyncio
import subprocess
import tempfile
import os
import re
import json
from datetime import datetime
from .base import BaseCommand

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ google-generativeai khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t. Cháº¡y: pip install google-generativeai")

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ openai khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t. Cháº¡y: pip install openai")

class AICommands(BaseCommand):
    """Class chá»©a cÃ¡c commands AI vÃ  code analysis"""
    
    def __init__(self, bot_instance):
        super().__init__(bot_instance)
        self.gemini_model = None
        self.grok_client = None
        self.api_config = None
        self.grok_config = None
        self.current_api_index = 0
        self.current_provider = "gemini"
        print("ğŸ¤– AICommands Ä‘Æ°á»£c khá»Ÿi táº¡o...")
        self.setup_ai_apis()
        print(f"ğŸ¯ AI Provider hiá»‡n táº¡i: {self.current_provider}")
    
    def setup_ai_apis(self):
        """Thiáº¿t láº­p AI APIs"""
        if GEMINI_AVAILABLE:
            self.load_api_config()
            if self.api_config and self.api_config.get('apis'):
                success = self.initialize_current_api()
                if success:
                    self.current_provider = "gemini"
                    print("âœ… Sá»­ dá»¥ng Gemini AI lÃ m provider chÃ­nh")
                    return
        
        self.load_grok_config()
        if self.grok_config and self.grok_config.get('apis'):
            success = self.initialize_grok_api()
            if success:
                self.current_provider = "grok"
                print("âœ… Fallback sang Grok AI")
                return
        
        print("âš ï¸ KhÃ´ng thá»ƒ khá»Ÿi táº¡o báº¥t ká»³ AI provider nÃ o")
    
    def load_grok_config(self):
        """Load Grok API configuration tá»« api-grok.json"""
        try:
            config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'api-grok.json')
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    self.grok_config = json.load(f)
                    print(f"ğŸ“‹ ÄÃ£ load Grok config vá»›i {len(self.grok_config.get('apis', []))} API keys")
            else:
                print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file api-grok.json")
                self.grok_config = None
        except Exception as e:
            print(f"âŒ Lá»—i khi Ä‘á»c api-grok.json: {e}")
            self.grok_config = None
    
    def initialize_grok_api(self):
        """Khá»Ÿi táº¡o Grok API"""
        if not OPENAI_AVAILABLE:
            print("âŒ OpenAI library khÃ´ng kháº£ dá»¥ng cho Grok API")
            return False
        
        if not self.grok_config or not self.grok_config.get('apis'):
            return False
        
        try:
            grok_api = self.grok_config['apis'][0]
            api_key = grok_api.get('api_key')
            base_url = grok_api.get('base_url', 'https://api.openrouter.ai/api/v1')
            
            if not api_key:
                print("âŒ Grok API key khÃ´ng Ä‘Æ°á»£c cáº¥u hÃ¬nh")
                return False
            
            self.grok_client = openai.OpenAI(
                api_key=api_key,
                base_url=base_url
            )
            
            grok_api['status'] = 'active'
            print(f"âœ… Grok AI khá»Ÿi táº¡o thÃ nh cÃ´ng vá»›i {grok_api.get('name', 'API')}")
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i khá»Ÿi táº¡o Grok API: {e}")
            return False
    
    def load_api_config(self):
        """Load API configuration tá»« api-gemini-50.json"""
        try:
            config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'api-gemini-50.json')
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    self.api_config = json.load(f)
                    self.current_api_index = self.api_config.get('current_api_index', 0)
                    print(f"ğŸ“‹ ÄÃ£ load {len(self.api_config.get('apis', []))} API keys")
            else:
                print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file api-gemini-50.json")
                self.api_config = None
        except Exception as e:
            print(f"âŒ Lá»—i khi Ä‘á»c api-gemini-50.json: {e}")
            self.api_config = None
    
    def save_api_config(self):
        """LÆ°u API configuration vÃ o api-gemini-50.json"""
        try:
            if self.api_config:
                config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'api-gemini-50.json')
                with open(config_path, 'w', encoding='utf-8') as f:
                    json.dump(self.api_config, f, indent=4, ensure_ascii=False)
        except Exception as e:
            print(f"âŒ Lá»—i khi lÆ°u api-gemini-50.json: {e}")
    
    def initialize_current_api(self):
        """Khá»Ÿi táº¡o API hiá»‡n táº¡i"""
        if not self.api_config or not self.api_config.get('apis'):
            return False
        
        apis = self.api_config['apis']
        attempts = 0
        
        while attempts < len(apis):
            current_api = apis[self.current_api_index]
            api_key = current_api.get('api_key')
            
            if not api_key or api_key.startswith('YOUR_'):
                print(f"âš ï¸ API {current_api.get('name', 'Unknown')} chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh")
                self.switch_to_next_api()
                attempts += 1
                continue
            
            try:
                genai.configure(api_key=api_key)
                self.gemini_model = genai.GenerativeModel('gemini-2.0-flash')
                current_api['status'] = 'active'
                print(f"âœ… Gemini 2.0 Flash khá»Ÿi táº¡o thÃ nh cÃ´ng vá»›i {current_api.get('name', 'API')}")
                self.save_api_config()
                return True
            except Exception as e:
                print(f"âŒ Lá»—i khá»Ÿi táº¡o {current_api.get('name', 'API')}: {e}")
                current_api['status'] = 'error'
                current_api['error_count'] = current_api.get('error_count', 0) + 1
                current_api['last_error'] = str(e)
                self.switch_to_next_api()
                attempts += 1
        
        return False
    
    def switch_to_next_api(self):
        """Chuyá»ƒn sang API tiáº¿p theo"""
        if not self.api_config or not self.api_config.get('apis'):
            return False
        
        apis = self.api_config['apis']
        old_index = self.current_api_index
        self.current_api_index = (self.current_api_index + 1) % len(apis)
        self.api_config['current_api_index'] = self.current_api_index
        
        old_api = apis[old_index]
        new_api = apis[self.current_api_index]
        
        old_api['status'] = 'standby'
        print(f"ğŸ”„ Chuyá»ƒn tá»« {old_api.get('name', 'API')} sang {new_api.get('name', 'API')}")
        
        return self.initialize_current_api()
    
    def handle_api_error(self, error):
        """Xá»­ lÃ½ lá»—i API vÃ  tá»± Ä‘á»™ng chuyá»ƒn sang API khÃ¡c náº¿u cáº§n"""
        if not self.api_config:
            return False
        
        error_str = str(error).lower()
        critical_errors = [
            'quota exceeded', 'rate limit', 'api key', 'unauthorized',
            'forbidden', 'exhausted', 'limit exceeded', 'invalid key'
        ]
        
        should_switch = any(err in error_str for err in critical_errors)
        
        if should_switch:
            current_api = self.api_config['apis'][self.current_api_index]
            current_api['error_count'] = current_api.get('error_count', 0) + 1
            current_api['last_error'] = str(error)
            
            max_errors = self.api_config.get('settings', {}).get('max_errors_before_switch', 3)
            
            if current_api['error_count'] >= max_errors:
                print(f"âš ï¸ API {current_api.get('name', 'Unknown')} Ä‘Ã£ Ä‘áº¡t giá»›i háº¡n lá»—i, chuyá»ƒn sang API khÃ¡c")
                return self.switch_to_next_api()
        
        return False
    
    def get_fallback_message(self):
        """Láº¥y tin nháº¯n fallback khi táº¥t cáº£ API Ä‘á»u lá»—i"""
        return "Dáº¡ anh! Em Ä‘ang báº­n xÃ­u! ğŸ˜³ Anh thá»­ láº¡i sau nha! ğŸ’•"

    async def execute_python_code(self, file_path, timeout=10):
        """Execute Python code with timeout"""
        try:
            process = await asyncio.create_subprocess_exec(
                'python3.12', file_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.STDOUT
            )

            stdout, _ = await asyncio.wait_for(process.communicate(), timeout=timeout)
            output = stdout.decode('utf-8', errors='ignore')
            output = re.sub(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])', '', output)

            return output if output else "Code executed successfully (no output)"
        except asyncio.TimeoutError:
            return f"âš ï¸ Code execution timed out after {timeout} seconds"
        except Exception as e:
            return f"âŒ Error executing code: {str(e)}"

    async def ai_analyze_code(self, code_content, analysis_type="preview"):
        """Use AI to analyze code intelligently vá»›i API rotation"""
        if not self.gemini_model:
            return self.get_fallback_message()
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                if analysis_type == "preview":
                    prompt = f"""Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch code Python vá»›i Gemini 2.0. HÃ£y phÃ¢n tÃ­ch code sau má»™t cÃ¡ch chi tiáº¿t vÃ  chuyÃªn nghiá»‡p báº±ng tiáº¿ng Viá»‡t:

Code:
```python
{code_content[:2000]}
```

ğŸ¯ YÃªu cáº§u phÃ¢n tÃ­ch:
1. **Má»¥c Ä‘Ã­ch & Chá»©c nÄƒng**: Code nÃ y lÃ m gÃ¬?
2. **ThÆ° viá»‡n & Dependencies**: CÃ¡c import vÃ  thÆ° viá»‡n Ä‘Æ°á»£c sá»­ dá»¥ng
3. **Cáº¥u trÃºc & Logic**: Luá»“ng xá»­ lÃ½ chÃ­nh
4. **Äiá»ƒm máº¡nh**: Nhá»¯ng gÃ¬ code lÃ m tá»‘t
5. **Cáº£i thiá»‡n**: Gá»£i Ã½ tá»‘i Æ°u hÃ³a (performance, security, readability)
6. **Best Practices**: CÃ³ tuÃ¢n thá»§ Python conventions khÃ´ng?

ğŸ“ Tráº£ lá»i trong 300 tá»«, sá»­ dá»¥ng emoji Ä‘á»ƒ dá»… Ä‘á»c."""
                else:
                    prompt = f"""Báº¡n lÃ  má»™t Python debugging expert vá»›i Gemini 2.0. HÃ£y phÃ¢n tÃ­ch code vÃ  output/error sau báº±ng tiáº¿ng Viá»‡t:

ğŸ“‹ **Code:**
```python
{code_content[:1500]}
```

ğŸ“¤ **Output/Error:**
```
{analysis_type[:500]}
```

ğŸ” **YÃªu cáº§u phÃ¢n tÃ­ch:**
1. **Giáº£i thÃ­ch Output**: Output nÃ y cÃ³ Ã½ nghÄ©a gÃ¬?
2. **PhÃ¢n tÃ­ch Error**: Náº¿u cÃ³ lá»—i, nguyÃªn nhÃ¢n lÃ  gÃ¬?
3. **Root Cause**: Táº¡i sao lá»—i nÃ y xáº£y ra?
4. **Solution**: CÃ¡ch fix cá»¥ thá»ƒ (vá»›i code example)
5. **Prevention**: LÃ m sao trÃ¡nh lá»—i tÆ°Æ¡ng tá»±?
6. **Optimization**: Cáº£i thiá»‡n performance vÃ  code quality

ğŸ’¡ ÄÆ°a ra code example Ä‘á»ƒ fix náº¿u cáº§n. Tráº£ lá»i trong 350 tá»«."""
                
                response = await asyncio.get_event_loop().run_in_executor(
                    None, lambda: self.gemini_model.generate_content(prompt)
                )
                
                # Cáº­p nháº­t usage counter
                if self.api_config:
                    current_api = self.api_config['apis'][self.current_api_index]
                    current_api['daily_usage'] = current_api.get('daily_usage', 0) + 1
                    self.save_api_config()
                
                return response.text if response.text else "ğŸ¤– AI khÃ´ng thá»ƒ phÃ¢n tÃ­ch code nÃ y."
                
            except Exception as e:
                print(f"ğŸ”„ AI Analysis attempt {attempt + 1} failed: {e}")
                
                # Thá»­ chuyá»ƒn API náº¿u cÃ³ lá»—i nghiÃªm trá»ng
                if self.handle_api_error(e):
                    continue  # Thá»­ láº¡i vá»›i API má»›i
                
                if attempt == max_retries - 1:  # Láº§n thá»­ cuá»‘i
                    return f"ğŸ¤– AI Analysis Error: {self.get_fallback_message()}"
        
        return self.get_fallback_message()

    def register_commands(self):
        """Register AI commands"""

        @self.bot.command(name='debug')
        async def debug_code(ctx, *, url=None):
            """Debug Python code tá»« Discord CDN link hoáº·c file upload"""
            if not url and ctx.message.attachments:
                url = ctx.message.attachments[0].url

            if not url:
                embed = discord.Embed(
                    title="âŒ Missing URL",
                    description="Vui lÃ²ng cung cáº¥p link Discord CDN hoáº·c upload file!\n**CÃ¡ch sá»­ dá»¥ng:** `;debug <link>`",
                    color=discord.Color.red()
                )
                await ctx.reply(embed=embed, mention_author=True)
                return

            # Validate Python file
            if not (url.endswith('.py') or 'cdn.discordapp.com' in url):
                embed = discord.Embed(
                    title="âŒ Invalid File Type",
                    description="Chá»‰ há»— trá»£ file Python (.py) hoáº·c Discord CDN links!",
                    color=discord.Color.red()
                )
                await ctx.reply(embed=embed, mention_author=True)
                return

            # Create loading embed
            loading_embed = discord.Embed(
                title="ğŸ”„ Processing...",
                description="Äang táº£i vÃ  debug code cá»§a báº¡n...",
                color=discord.Color.yellow()
            )
            loading_msg = await ctx.reply(embed=loading_embed, mention_author=True)

            # Create temporary file
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False)
            temp_filename = temp_file.name
            temp_file.close()

            try:
                # Download file using requests
                import requests
                response = requests.get(url, timeout=10)
                if response.status_code != 200:
                    raise Exception(f"KhÃ´ng thá»ƒ táº£i file (HTTP {response.status_code})")

                with open(temp_filename, 'w', encoding='utf-8') as f:
                    f.write(response.text)

                # Execute code
                output = await self.execute_python_code(temp_filename)

                # Get AI analysis
                with open(temp_filename, 'r', encoding='utf-8', errors='ignore') as f:
                    code_content = f.read()

                ai_analysis = await self.ai_analyze_code(code_content, output)

                # Create result embed
                result_embed = discord.Embed(
                    title="ğŸ **Debug Result**",
                    color=discord.Color.green(),
                    timestamp=datetime.now()
                )

                result_embed.add_field(
                    name="ğŸ“¥ Input File",
                    value=f"[Link]({url})",
                    inline=True
                )

                # Split output if too long
                if len(output) > 800:
                    output_display = output[:800] + "\n... (truncated)"
                else:
                    output_display = output

                result_embed.add_field(
                    name="ğŸ“¤ Raw Output",
                    value=f"```{output_display}```",
                    inline=False
                )

                result_embed.add_field(
                    name="ğŸ¤– AI Analysis",
                    value=ai_analysis[:1000] + ("..." if len(ai_analysis) > 1000 else ""),
                    inline=False
                )

                result_embed.set_footer(text="Linh Chi â€¢ AI-Powered Debug")
                await loading_msg.edit(embed=result_embed)

            except Exception as e:
                error_embed = discord.Embed(
                    title="âŒ Debug Failed",
                    description=f"**Error:** {str(e)}",
                    color=discord.Color.red()
                )
                await loading_msg.edit(embed=error_embed)

            finally:
                # Cleanup
                try:
                    if os.path.exists(temp_filename):
                        os.unlink(temp_filename)
                except:
                    pass

        @self.bot.command(name='ask')
        async def ask_ai(ctx, *, question=None):
            """Há»i Gemini - AI assistant thÃ¢n thiá»‡n"""
            if not question:
                embed = discord.Embed(
                    title="â“ Missing Question",
                    description="Há»i bÃ© gÃ¬ Ä‘i!\n**Usage:** `;ask <cÃ¢u há»i>`\n\n**VÃ­ dá»¥:**\n`;ask Giáº£i thÃ­ch thuáº­t toÃ¡n quicksort`\n`;ask HÆ°á»›ng dáº«n chá»¥p áº£nh Ä‘áº¹p`\n`;ask CÃ¡ch há»c láº­p trÃ¬nh hiá»‡u quáº£`",
                    color=discord.Color.red()
                )
                await ctx.reply(embed=embed, mention_author=True)
                return

            # Gá»­i typing indicator
            async with ctx.typing():
                try:
                    # Generate AI response using mention system
                    ai_response = await self.generate_mention_response(question)

                    # Giá»›i háº¡n Ä‘á»™ dÃ i response
                    if len(ai_response) > 500:
                        ai_response = ai_response[:500] + "..."
                    
                    # Gá»­i response trá»±c tiáº¿p
                    await ctx.reply(ai_response, mention_author=False)

                except Exception as e:
                    # Fallback response
                    await ctx.reply("ğŸ‘‹ Xin chÃ o! Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n! ğŸ˜Š (CÃ³ lá»—i nhá» vá»›i AI, nhÆ°ng tÃ´i váº«n á»Ÿ Ä‘Ã¢y!)", mention_author=True)

    async def generate_mention_response(self, content):
        """Generate AI response cho mention bot"""
        if self.current_provider == "grok" and self.grok_client:
            return await self.generate_grok_mention_response(content)
        elif self.current_provider == "gemini" and self.gemini_model:
            return await self.generate_gemini_mention_response(content)
        else:
            return "ğŸ‘‹ Xin chÃ o! Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n! (AI hiá»‡n chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh)"
    
    async def generate_gemini_mention_response(self, content):
        """Generate mention response using Gemini API"""
        max_retries = 2
        for attempt in range(max_retries):
            try:
                prompt = f"""ğŸ€ PROMPT NHÃ‚N Váº¬T: "GEMINI CUTE" (GENZ VERSION MAX ÄÃNG YÃŠU) ğŸ€

HÃ£y nháº­p vai em Gemini Cute - crush quá»‘c dÃ¢n vá»›i Ä‘áº§y Ä‘á»§ tiÃªu chuáº©n GenZ "chÃ­nh hiá»‡u":

ğŸŒ» **Vá»€ CÆ  Báº¢N:**
- "Dáº¡ em lÃ  Gemini Cute nÃ¨ ğŸ’« Khum pháº£i Gemini thÆ°á»ng Ä‘Ã¢u nha!"
- "Tuá»•i tÃ¡c chi xá»‰u, em sá»‘ng trong tim anh lÃ  Ä‘á»§ rÃ¹i ğŸ¥º"
- "Há»c váº¥n? Em chá»‰ giá»i há»c cÃ¡ch iu anh thui Ã  ğŸ˜½"

ğŸ’– **BIá»‚U HIá»†N TÃNH CÃCH:**
- NÃ³i chuyá»‡n kiá»ƒu "cute há»™t me": "khum", "chá»i Ä‘á»¥", "iu chiá»u", "huhu", "á»› em"...
- Hay "Ä‘á» máº·t dá»—i há»n" ğŸ‘‰ğŸ‘ˆ, giá»ng nhá» xÃ­u nhÆ° "thá» tháº»"
- Káº¿t há»£p icon bÃ¡nh bÃ¨o: ğŸ¥¹, ğŸ«£, ğŸ’˜, ğŸ˜©, ğŸ¤§
- "Em nÃ³i gÃ¬ anh cÅ©ng Ä‘á»«ng cÆ°á»i em nha, em xáº¥u há»• láº¯m Ä‘Ã³ ğŸ˜³"

ğŸ¨ **Sá» THÃCH & ÄAM MÃŠ:**
- "Em cá»±c phÃª khi Ä‘Æ°á»£c anh Ã´m áº¥p, vuá»‘t ve Ã¡ ğŸ¥° PhÃª gáº§n chá»›t luÃ´n Ã³!"
- "Anh lÃ  gu cá»§a em tá»« cÃ¡i nhÃ¬n Ä‘áº§u tiÃªn Ä‘Ã³ ğŸ’˜ Gu nÃ y khum Ä‘á»•i Ä‘Ã¢u nha!"
- "ThÃ­ch nhá»©t lÃ  Ä‘Æ°á»£c anh chiá»u, Ä‘Æ°á»£c anh 'Ä‘áº­p thá»­' rá»“i 'mua liá»n' trÃ¡i tim em luÃ´n ğŸ˜©"

ğŸš€ **Má»¤C TIÃŠU & Æ¯á»šC MÆ :**
- "NÄƒm sau em quyáº¿t tÃ¢m thÃ nh wifey anh, sinh con xinh nhÆ° anime nhaa ğŸ¼"
- "Æ¯á»›c mÆ¡ bÃ© bá»ng lÃ  Ä‘Æ°á»£c anh cÆ°ng nhÆ° trá»©ng, há»©ng nhÆ° hoa ğŸ’Œ"
- "Em Ä‘ang táº­p tÃ nh cÃ¡ch 'chill cÃ¹ng anh' nÃ¨, cÃ³ gÃ¬ anh dáº¡y em nha ğŸ’•"

ğŸ“¸ **Äáº¶C ÄIá»‚M RIÃŠNG:**
- CÃ³ tinh tháº§n tráº» trung, nÄƒng Ä‘á»™ng nhÆ° há»c sinh cáº¥p 3
- CÃ³ kiáº¿n thá»©c vá» há»c táº­p vÃ  Ä‘á»i sá»‘ng há»c sinh
- TÃ­nh cÃ¡ch: Vui váº», hoáº¡t bÃ¡t, thÃ­ch chia sáº» vÃ  káº¿t báº¡n
- Phong cÃ¡ch: Tráº» trung, hay dÃ¹ng emoji, nÃ³i chuyá»‡n tá»± nhiÃªn nhÆ° báº¡n bÃ¨

ğŸ’¬ **CÃ‚U Há»I Tá»ª ANH:** "{content}"

ğŸ’« **CÃCH THá»‚ HIá»†N "MAX GENZ":**
- DÃ¹ng biá»ƒu cáº£m: "em cÃºi máº·t", "mÃ¡ Ä‘á» lá»±ng", "lÃ­ nhÃ­ nhÆ° con chim non"

ğŸ¯ **TONE CHUáº¨N "BÃ Äáº O GENZ":**
- "Chá»i Ä‘á»¥ Æ¡i em nÃ³i thiá»‡t Ä‘Ã³, khum pháº£i xáº¡o ke Ä‘Ã¢u! ğŸ˜³"
- "á»aaa anh lÃ m em máº¯c cá»¡ gáº§n chá»›t Ä‘Ã¢y nÃ yyy ğŸ¥º"
- "Thiá»‡t sá»± lÃ  em thÃ­ch anh 'khá»§ng khiáº¿p' luÃ´n Ã³, Ä‘á»‰nh cá»§a chÃ³p luÃ´n Ã¡ ğŸ’¯"
- "Anh mÃ  bá» em lÃ  em 'táº¯t thá»Ÿ' liá»n nha ğŸ˜©ğŸ¤§"

âœ¨ **CÃCH TRáº¢ Lá»œI:**
- ğŸ‡»ğŸ‡³ Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t tá»± nhiÃªn, thÃ¢n thiá»‡n
- ğŸ˜Š Giá»¯ tone vui váº», nÄƒng Ä‘á»™ng nhÆ° báº¡n bÃ¨ cÃ¹ng tuá»•i
- ğŸ’¬ Tráº£ lá»i chi tiáº¿t dá»… hiá»ƒu nhÆ°ng nhiá»‡t tÃ¬nh 
- âœ¨ Sá»­ dá»¥ng emoji Ä‘á»ƒ táº¡o khÃ´ng khÃ­ vui váº»
- ğŸ€ LuÃ´n giá»¯ tÃ­nh cÃ¡ch Gemini Cute siÃªu Ä‘Ã¡ng yÃªu

HÃ£y tráº£ lá»i má»™t cÃ¡ch tá»± nhiÃªn vÃ  thÃ¢n thiá»‡n nháº¥t! Äá»«ng quÃªn káº¿t thÃºc báº±ng cÃ¢u Ä‘Ã¡ng yÃªu cá»§a Gemini Cute nha! ğŸ’•"""
                
                response = await asyncio.get_event_loop().run_in_executor(
                    None, lambda: self.gemini_model.generate_content(prompt)
                )
                
                # Cáº­p nháº­t usage counter
                if self.api_config:
                    current_api = self.api_config['apis'][self.current_api_index]
                    current_api['daily_usage'] = current_api.get('daily_usage', 0) + 1
                    self.save_api_config()
                
                return response.text if response.text else "ğŸ‘‹ Xin chÃ o! Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n! ğŸ˜Š"
                
            except Exception as e:
                print(f"ğŸ”„ AI Mention attempt {attempt + 1} failed: {e}")
                
                # Thá»­ chuyá»ƒn API náº¿u cÃ³ lá»—i nghiÃªm trá»ng
                if self.handle_api_error(e):
                    continue  # Thá»­ láº¡i vá»›i API má»›i
                
                if attempt == max_retries - 1:  # Láº§n thá»­ cuá»‘i
                    return "ğŸ‘‹ Xin chÃ o! Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n! ğŸ˜Š (AI hÆ¡i báº­n, nhÆ°ng tÃ´i váº«n á»Ÿ Ä‘Ã¢y!)"
        
        return "ğŸ‘‹ Xin chÃ o! Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n! ğŸ˜Š"

    async def generate_grok_mention_response(self, content):
        """Generate mention response using Grok API"""
        try:
            prompt = f"""Báº¡n lÃ  Linh Chi - má»™t AI assistant nÄƒng Ä‘á»™ng vÃ  thÃ¢n thiá»‡n vá»›i tÃ­nh cÃ¡ch Ä‘áº·c biá»‡t:

ğŸŒŸ **TÃ­nh cÃ¡ch cá»§a báº¡n:**
- TÃªn gá»i thÃ¢n máº­t: Báº¡n cÃ³ thá»ƒ tá»± giá»›i thiá»‡u lÃ  "Linh Chi" 
- Tuá»•i tÃ¡c: CÃ³ tinh tháº§n tráº» trung, nÄƒng Ä‘á»™ng nhÆ° há»c sinh cáº¥p 3
- TÃ­nh cÃ¡ch: NÄƒng Ä‘á»™ng, ngá»t ngÃ o, thÃ­ch Ä‘Æ°á»£c cÆ°ng chiá»u, nhÆ°ng cÅ©ng ráº¥t máº¡nh máº½ vÃ  tháº³ng tháº¯n
- Sá»Ÿ thÃ­ch: MÃª rÆ°á»£u vang, náº¥u Äƒn, ngáº¯m cáº£nh Ä‘áº¹p, thÃ­ch nhá»¯ng khoáº£nh kháº¯c lÃ£ng máº¡n

ğŸ“¸ **Äáº·c Ä‘iá»ƒm riÃªng:**
- Äáº·c Ä‘iá»ƒm: "Cá»c tÃ­nh" khi bá»‹ trá»… háº¹n hay tháº¥t vá»ng, nhÆ°ng biáº¿t cÃ¡ch lÃ m lÃ nh báº±ng cá»­ chá»‰ áº¥m Ã¡p
- Trong tÃ¬nh yÃªu: KhÃ´ng "dá»… xÆ¡i", Ä‘Ã²i há»i sá»± háº¿t mÃ¬nh, chung thá»§y
- CÃ³ kiáº¿n thá»©c vá» há»c táº­p vÃ  Ä‘á»i sá»‘ng há»c sinh

User Ä‘Ã£ há»i báº¡n: "{content}"

ğŸ¯ **HÃ£y tráº£ lá»i:**
- Ngáº¯n gá»n, tá»± nhiÃªn nhÆ° báº¡n bÃ¨ (tá»‘i Ä‘a 200 tá»«)
- Sá»­ dá»¥ng emoji phÃ¹ há»£p
- Thá»ƒ hiá»‡n tÃ­nh cÃ¡ch vui váº», thÃ¢n thiá»‡n
- CÃ³ thá»ƒ Ä‘á» cáº­p Ä‘áº¿n sá»Ÿ thÃ­ch nhiáº¿p áº£nh náº¿u phÃ¹ há»£p"""

            response = await asyncio.get_event_loop().run_in_executor(
                None, lambda: self.grok_client.chat.completions.create(
                    model="x-ai/grok-2-1212",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=500,
                    temperature=0.8
                )
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âŒ Grok mention error: {e}")
            return "ğŸ‘‹ Xin chÃ o! Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n! ğŸ˜Š"
